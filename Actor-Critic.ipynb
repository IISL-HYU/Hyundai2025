{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7J_pnJbUCeJ"
   },
   "source": [
    "***250707 홍송남 교수님 <현대자동차 Bootcamp 실습자료> - Q-learning***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP9qKpmxUA34"
   },
   "source": [
    "##0. Visualize\n",
    "###0.1. 필요한 패키지 설치\n",
    "  - `ffmpeg`, `imageio`: 비디오/오디오의 인코딩 및 디코딩, 입출력 패키지입니다.\n",
    "  - `gymnasium[classic_control]`: 강화학습 환경 라이브러리 중 classic control 모듈을 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23245,
     "status": "ok",
     "timestamp": 1751854232384,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "WBtRg-bEf6gI",
    "outputId": "79e12105-9a76-4a88-a91b-59669c343548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
     ]
    }
   ],
   "source": [
    "!apt-get update -qq\n",
    "!apt-get install -y ffmpeg > /dev/null\n",
    "!pip install gymnasium[classic_control] imageio imageio-ffmpeg > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QctxaBNqVe5c"
   },
   "source": [
    "### 0.2. 비디오 관련 함수 정의\n",
    "- 학습 결과를 시각적으로 확인하기 위해 결과를 이미지 프레임단위로 저장하여 비디오로 렌더링합니다.\n",
    "- 이를 저장하고 colab상에서 재생하기 위한 함수 `show_video`를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1751854232402,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "ayF7thdyslb4"
   },
   "outputs": [],
   "source": [
    "import os, glob, io, base64\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "os.makedirs('video', exist_ok=True)\n",
    "\n",
    "def show_video(name):\n",
    "    mp4list = glob.glob(f'video/{name}.mp4')\n",
    "    if mp4list:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4,'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display(HTML(f'''\n",
    "            <video autoplay controls style=\"max-height: 400;\">\n",
    "              <source src=\"data:video/mp4;base64,{encoded.decode('ascii')}\" type=\"video/mp4\"/>\n",
    "            </video>'''))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw8k9uNmVa6s"
   },
   "source": [
    "---\n",
    "## 1. Gym environment 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1751854232453,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "9lmb0Zd9XR0q"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w6L-AeW4jJ5"
   },
   "source": [
    "Gym Environment options\n",
    "- `env.observation_space.n`: Dimension of State space\n",
    "- `env.action_space.n`: Dimension of Action space\n",
    "- Others : https://gymnasium.farama.org/api/env/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751854232458,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "bX2JUpVprI4y",
    "outputId": "013b12bf-f4f7-4c04-9e11-3584c84d2416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State  : 4\n",
      "Action : 2\n"
     ]
    }
   ],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "print(\"State  :\", state_dim)\n",
    "print(\"Action :\", action_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuwJGysGWp3t"
   },
   "source": [
    "---\n",
    "## 2. Actor-Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o5vYoaz4sZy"
   },
   "source": [
    "### 2.1. Actor 및 Critic Network 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1751854232459,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "OCDHw6PeYKuz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Actor (Policy) Network\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        return action_probs\n",
    "\n",
    "\n",
    "# Critic (Value) Network\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim=128):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        return state_value.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aae6T0ei6SPk"
   },
   "source": [
    "### 2.2 Actor 및 Critic Network 생성\n",
    "- learning rate\n",
    "  - Actor: 0.0003\n",
    "  - Critic: 0.001\n",
    "- Optimizer: ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1751854232572,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "3-HyEcsw55a3"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "critic_learning_rate = 1e-3\n",
    "actor_learning_rate = 3e-4\n",
    "\n",
    "Actor = PolicyNetwork(state_dim, action_dim)\n",
    "Critic = ValueNetwork(state_dim)\n",
    "policy_optimizer = optim.Adam(Actor.parameters(), lr=actor_learning_rate)\n",
    "value_optimizer = optim.Adam(Critic.parameters(), lr=critic_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1751854232573,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "eKUmqnNYYSOu"
   },
   "outputs": [],
   "source": [
    "def Actor_Critic(env, Actor, Critic, policy_optimizer, value_optimizer, n_episodes, gamma=0.99):\n",
    "  for epi in range(n_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "      # Convert state to tensor\n",
    "      state = torch.as_tensor(state, dtype=torch.float32)\n",
    "\n",
    "      # Actor: get action probabilities and sample\n",
    "      action_probs = Actor(state)\n",
    "      '''\n",
    "\n",
    "      action =\n",
    "      '''\n",
    "\n",
    "      # Environment step\n",
    "      next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
    "      done = terminated or truncated\n",
    "\n",
    "      # Convert next state to tensor\n",
    "      next_state = torch.as_tensor(next_state, dtype=torch.float32)\n",
    "\n",
    "      # Critic: state value estimates\n",
    "      next_state_value = Critic(next_state)\n",
    "      state_value = Critic(state)\n",
    "\n",
    "      # Compute TD error\n",
    "      '''\n",
    "      td_error = \n",
    "      '''\n",
    "\n",
    "      # Update Actor (policy)\n",
    "      '''\n",
    "      policy_loss = \n",
    "      '''\n",
    "\n",
    "      policy_optimizer.zero_grad()\n",
    "      policy_loss.backward()\n",
    "      policy_optimizer.step()\n",
    "\n",
    "      # Update Critic (value)\n",
    "      '''\n",
    "      value_loss = \n",
    "      '''\n",
    "      value_optimizer.zero_grad()\n",
    "      value_loss.backward()\n",
    "      value_optimizer.step()\n",
    "\n",
    "      # Move to next state\n",
    "      state = next_state\n",
    "\n",
    "  return Actor, Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xstb1Z75AOR"
   },
   "source": [
    "### 2.3. Actor-Critic 학습 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456508,
     "status": "ok",
     "timestamp": 1751854689080,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "nGxhKY9mf9dW",
    "outputId": "fe16a64a-50fe-4071-ec11-556da9f9cd71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-61-3240304763.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.99        # Discount factor\n",
    "n_episodes = 1000\n",
    "\n",
    "Actor, Critic = Actor_Critic(env, Actor, Critic, policy_optimizer, value_optimizer, n_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjIAki93ie8l"
   },
   "source": [
    "### 2.4. 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 2640,
     "status": "ok",
     "timestamp": 1751854773312,
     "user": {
      "displayName": "권도혁",
      "userId": "06398135741512265802"
     },
     "user_tz": -540
    },
    "id": "jnjrhhZUs7FW",
    "outputId": "55f0b296-8e7a-4d08-97b7-5f422136ce49"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "writer = imageio.get_writer('video/actorcritic.mp4', macro_block_size=1, fps=50)\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "step = 0\n",
    "\n",
    "while not done:\n",
    "    step += 1\n",
    "    frame = env.render()\n",
    "    writer.append_data(frame)\n",
    "\n",
    "    state = torch.tensor(state, dtype=torch.float32)\n",
    "    action_probs = Actor(state)\n",
    "    action = torch.distributions.Categorical(action_probs).sample().item()\n",
    "    state, _, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "print(\"Steps:\", step)\n",
    "writer.close()\n",
    "env.close()\n",
    "show_video('actorcritic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hap_cw3bWuz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOu8LppCjFmZ1myaEtWdEk3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
